{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"75DqqHJiIvC2"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3336,"status":"ok","timestamp":1742719129701,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"5ba8y6Q5J38f","outputId":"c552061a-8dda-44e4-ae09-ebbb45cd309e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting cftime\n","  Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n","Requirement already satisfied: numpy>1.13.3 in /usr/local/lib/python3.11/dist-packages (from cftime) (2.0.2)\n","Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m1.1/1.4 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: cftime\n","Successfully installed cftime-1.6.4.post1\n"]}],"source":["!pip install cftime"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Rn7Q3FZI2qA"},"outputs":[],"source":["import xarray as xr\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5252,"status":"ok","timestamp":1742719443897,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"pDtNMOOZI45O","outputId":"310cd735-1bfe-450f-c856-c7f12b19ba9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["<xarray.Dataset> Size: 726MB\n","Dimensions:                         (time: 7, lon: 3600, lat: 1800)\n","Coordinates:\n","  * lat                             (lat) float32 7kB -89.95 -89.85 ... 89.95\n","  * lon                             (lon) float32 14kB -179.9 -179.9 ... 179.9\n","  * time                            (time) object 56B 2024-01-01 00:00:00 ......\n","Data variables:\n","    precipitationQualityIndex       (time, lon, lat) float32 181MB nan ... nan\n","    precipitation                   (time, lon, lat) float32 181MB nan ... nan\n","    probabilityLiquidPrecipitation  (time, lon, lat) float32 181MB 0.0 ... 3.0\n","    randomError                     (time, lon, lat) float32 181MB nan ... nan\n","Attributes:\n","    FileHeader:                      DOI=10.5067/GPM/IMERG/3B-MONTH/07;\\nDOIa...\n","    FileInfo:                        DataFormatVersion=7e;\\nTKCodeBuildVersio...\n","    Grid.GridHeader:                 BinMethod=ARITHMETIC_MEAN;\\nRegistration...\n","    Grid.fullnamepath:               /Grid\n","    DODS_EXTRA.Unlimited_Dimension:  time\n","    history:                         2025-03-23 06:23:20 GMT hyrax-1.17.1 htt...\n","    history_json:                    [{\"$schema\":\"https:\\/\\/harmony.earthdata...\n"]}],"source":["import xarray as xr\n","import pandas as pd\n","\n","# List of all your .nc4 file paths\n","file_paths = [\n","    \"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/3B-MO.MS.MRG.3IMERG.20240101-S000000-E235959.01.V07B.HDF5.nc4\",\n","    \"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/3B-MO.MS.MRG.3IMERG.20240201-S000000-E235959.02.V07B.HDF5.nc4\",\n","    \"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/3B-MO.MS.MRG.3IMERG.20240301-S000000-E235959.03.V07B.HDF5.nc4\",\n","    \"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/3B-MO.MS.MRG.3IMERG.20240601-S000000-E235959.06.V07B.HDF5.nc4\",\n","    \"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/3B-MO.MS.MRG.3IMERG.20240701-S000000-E235959.07.V07B.HDF5.nc4\",  # Fixed filename\n","    \"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/3B-MO.MS.MRG.3IMERG.20240801-S000000-E235959.08.V07B.HDF5.nc4\",\n","    \"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/3B-MO.MS.MRG.3IMERG.20240901-S000000-E235959.09.V07B.HDF5.nc4\"\n","]\n","\n","# Open multiple files and merge along the time dimension\n","ds_list = [xr.open_dataset(f, decode_times=True) for f in file_paths]  # Using decode_times=True\n","merged_ds = xr.concat(ds_list, dim=\"time\")  # Merging along time axis\n","\n","# Close individual datasets to free memory\n","for ds in ds_list:\n","    ds.close()\n","\n","# Print merged dataset info\n","print(merged_ds)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1742719816226,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"N1LVbR8xI41p","outputId":"a8a4229f-4c1b-4342-e19b-49b7b8981ea6"},"outputs":[{"name":"stdout","output_type":"stream","text":["['2024-01-01T00:00:00.000000000' '2024-02-01T00:00:00.000000000'\n"," '2024-03-01T00:00:00.000000000' '2024-06-01T00:00:00.000000000'\n"," '2024-07-01T00:00:00.000000000' '2024-08-01T00:00:00.000000000'\n"," '2024-09-01T00:00:00.000000000']\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import xarray as xr\n","\n","# Convert cftime.DatetimeJulian to pandas datetime\n","time_values = merged_ds['time'].values  # Extract time values\n","\n","# Convert to string, then parse to datetime\n","converted_time = pd.to_datetime(time_values.astype(str))\n","\n","# Assign back to dataset\n","merged_ds = merged_ds.assign_coords(time=converted_time)\n","\n","# Print first few time values to verify\n","print(merged_ds['time'].values)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"13CmadNLMxZK"},"outputs":[],"source":["merged_ds.to_netcdf(\"merged_dataset.nc4\")  # Save merged file\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5346,"status":"ok","timestamp":1742720015218,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"Az508TLGNO4R","outputId":"fbc36ad0-785d-45a7-d5ad-28bc2afddfa9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processed dataset saved successfully!\n"]}],"source":["# Save the merged dataset with corrected time to a new .nc4 file\n","merged_ds.to_netcdf(\"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/merged_dataset.nc4\")\n","\n","print(\"Processed dataset saved successfully!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1742721394643,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"XcUB7HDuSh1r","outputId":"f96f5d3b-5e73-486a-eb90-1a7bbb91bcd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Frozen({'lon': <xarray.IndexVariable 'lon' (lon: 3600)> Size: 14kB\n","array([-179.95   , -179.85   , -179.75   , ...,  179.75   ,  179.84999,\n","        179.95   ], dtype=float32)\n","Attributes:\n","    DimensionNames:  lon\n","    Units:           degrees_east\n","    units:           degrees_east\n","    standard_name:   longitude\n","    LongName:        Longitude at the center of\\n\\t\\t\\t0.10 degree grid inter...\n","    bounds:          lon_bnds\n","    axis:            X\n","    origname:        lon\n","    fullnamepath:    /Grid/lon, 'lat': <xarray.IndexVariable 'lat' (lat: 1800)> Size: 7kB\n","array([-89.95, -89.85, -89.75, ...,  89.75,  89.85,  89.95], dtype=float32)\n","Attributes:\n","    DimensionNames:  lat\n","    Units:           degrees_north\n","    units:           degrees_north\n","    standard_name:   latitude\n","    LongName:        Latitude at the center of\\n\\t\\t\\t0.10 degree grid interv...\n","    bounds:          lat_bnds\n","    axis:            Y\n","    origname:        lat\n","    fullnamepath:    /Grid/lat, 'precipitationQualityIndex': <xarray.Variable (time: 7, lon: 3600, lat: 1800)> Size: 181MB\n","[45360000 values with dtype=float32]\n","Attributes:\n","    DimensionNames:    time,lon,lat\n","    CodeMissingValue:  -9999.9\n","    origname:          precipitationQualityIndex\n","    fullnamepath:      /Grid/precipitationQualityIndex, 'precipitation': <xarray.Variable (time: 7, lon: 3600, lat: 1800)> Size: 181MB\n","[45360000 values with dtype=float32]\n","Attributes:\n","    DimensionNames:    time,lon,lat\n","    Units:             mm/hr\n","    units:             mm/hr\n","    CodeMissingValue:  -9999.9\n","    LongName:          Merged microwave-infrared-gauge precipitation estimate\n","    origname:          precipitation\n","    fullnamepath:      /Grid/precipitation, 'probabilityLiquidPrecipitation': <xarray.Variable (time: 7, lon: 3600, lat: 1800)> Size: 181MB\n","[45360000 values with dtype=float32]\n","Attributes:\n","    DimensionNames:    time,lon,lat\n","    Units:             percent\n","    units:             percent\n","    CodeMissingValue:  -9999\n","    LongName:          \\nProbability of liquid precipitation;  estimated with...\n","    origname:          probabilityLiquidPrecipitation\n","    fullnamepath:      /Grid/probabilityLiquidPrecipitation, 'randomError': <xarray.Variable (time: 7, lon: 3600, lat: 1800)> Size: 181MB\n","[45360000 values with dtype=float32]\n","Attributes:\n","    DimensionNames:    time,lon,lat\n","    Units:             mm/hr\n","    units:             mm/hr\n","    CodeMissingValue:  -9999.9\n","    LongName:          \\nRoot-mean-square error estimate for \\n              ...\n","    origname:          randomError\n","    fullnamepath:      /Grid/randomError, 'time': <xarray.IndexVariable 'time' (time: 7)> Size: 56B\n","array(['2024-01-01T00:00:00.000000000', '2024-02-01T00:00:00.000000000',\n","       '2024-03-01T00:00:00.000000000', '2024-06-01T00:00:00.000000000',\n","       '2024-07-01T00:00:00.000000000', '2024-08-01T00:00:00.000000000',\n","       '2024-09-01T00:00:00.000000000'], dtype='datetime64[ns]')})\n"]}],"source":["print(merged_ds.variables)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pKVPf0ZEXa8_"},"outputs":[],"source":["ds_india = merged_ds.sel(lat=slice(6, 38), lon=slice(68, 98))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":480,"status":"ok","timestamp":1742722739866,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"b8kPUyKaXp__","outputId":"cfe793c2-b0ef-449c-9704-e848218d5c4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["<xarray.Dataset> Size: 11MB\n","Dimensions:                         (lon: 300, lat: 320, time: 7)\n","Coordinates:\n","  * lon                             (lon) float32 1kB 68.05 68.15 ... 97.95\n","  * lat                             (lat) float32 1kB 6.05 6.15 ... 37.85 37.95\n","  * time                            (time) datetime64[ns] 56B 2024-01-01 ... ...\n","Data variables:\n","    precipitationQualityIndex       (time, lon, lat) float32 3MB ...\n","    precipitation                   (time, lon, lat) float32 3MB ...\n","    probabilityLiquidPrecipitation  (time, lon, lat) float32 3MB ...\n","    randomError                     (time, lon, lat) float32 3MB ...\n","Attributes:\n","    FileHeader:                      DOI=10.5067/GPM/IMERG/3B-MONTH/07;\\nDOIa...\n","    FileInfo:                        DataFormatVersion=7e;\\nTKCodeBuildVersio...\n","    Grid.GridHeader:                 BinMethod=ARITHMETIC_MEAN;\\nRegistration...\n","    Grid.fullnamepath:               /Grid\n","    DODS_EXTRA.Unlimited_Dimension:  time\n","    history:                         2025-03-23 06:23:20 GMT hyrax-1.17.1 htt...\n","    history_json:                    [{\"$schema\":\"https:\\/\\/harmony.earthdata...\n"]}],"source":["print(ds_india)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":475,"status":"ok","timestamp":1742722793307,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"QfedFm9-X3CC","outputId":"23efcca4-79b6-45fd-fafe-fb6118993066"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0 3.625000238418579\n"]}],"source":["print(ds_india[\"precipitation\"].min().values, ds_india[\"precipitation\"].max().values)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":640,"status":"ok","timestamp":1742723198226,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"_zBgR2B-YKCa","outputId":"2310eb43-30c1-4108-c746-5e8a888b88da"},"outputs":[{"name":"stdout","output_type":"stream","text":["         lon   lat       time  precipitationQualityIndex  precipitation  \\\n","0  68.049995  6.05 2024-01-01                       3.94          0.190   \n","1  68.049995  6.05 2024-02-01                       3.27          0.043   \n","2  68.049995  6.05 2024-03-01                       2.74          0.009   \n","3  68.049995  6.05 2024-06-01                       3.76          0.149   \n","4  68.049995  6.05 2024-07-01                       4.01          0.302   \n","\n","   probabilityLiquidPrecipitation  randomError  \n","0                           100.0        0.045  \n","1                           100.0        0.020  \n","2                           100.0        0.010  \n","3                           100.0        0.039  \n","4                           100.0        0.062  \n"]}],"source":["import pandas as pd\n","\n","# Convert xarray dataset to pandas dataframe\n","df = ds_india.to_dataframe().reset_index()\n","\n","# Display the first few rows\n","print(df.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":500,"status":"ok","timestamp":1742722907403,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"wfRXZbFeYSyP","outputId":"cb33a23a-bd0e-48af-8729-69d49d44be02"},"outputs":[{"name":"stdout","output_type":"stream","text":["        time  precipitation\n","0 2024-01-01       0.035103\n","1 2024-02-01       0.017206\n","2 2024-03-01       0.026772\n","3 2024-06-01       0.328494\n","4 2024-07-01       0.427952\n"]}],"source":["df_grouped = df.groupby(\"time\")[\"precipitation\"].mean().reset_index()\n","\n","print(df_grouped.head())  # Check the format\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":415,"status":"ok","timestamp":1742722953153,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"8zdYW9uDYeL6","outputId":"79ac3f3d-7aac-4678-8939-153210dc0a40"},"outputs":[{"name":"stdout","output_type":"stream","text":["        time  precipitation\n","0 2024-01-01       0.043571\n","1 2024-02-01       0.000000\n","2 2024-03-01       0.023290\n","3 2024-06-01       0.757861\n","4 2024-07-01       1.000000\n"]}],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","df_grouped[\"precipitation\"] = scaler.fit_transform(df_grouped[[\"precipitation\"]])\n","\n","print(df_grouped.head())  # Normalized data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":784,"status":"ok","timestamp":1742723005947,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"_60iBnHrYq8O","outputId":"f2548042-c65e-4b93-8dd1-4b2f0951d6a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["<DatetimeArray>\n","['2024-01-01 00:00:00', '2024-02-01 00:00:00', '2024-03-01 00:00:00',\n"," '2024-06-01 00:00:00', '2024-07-01 00:00:00', '2024-08-01 00:00:00',\n"," '2024-09-01 00:00:00']\n","Length: 7, dtype: datetime64[ns]\n"]}],"source":["# Print all unique time values in dataset\n","print(df[\"time\"].unique())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":444,"status":"ok","timestamp":1742723026586,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"m2RTLz-HYwCx","outputId":"a56f50b7-fd0a-4b45-c1a4-a57386df198d"},"outputs":[{"name":"stdout","output_type":"stream","text":["month\n","1    96000\n","2    96000\n","3    96000\n","6    96000\n","7    96000\n","8    96000\n","9    96000\n","Name: precipitation, dtype: int64\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/pandas/core/arrays/datetimes.py:666: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\n","  converted = ints_to_pydatetime(\n"]}],"source":["# Group data by month and count available entries\n","df[\"month\"] = pd.to_datetime(df[\"time\"]).dt.month\n","month_counts = df.groupby(\"month\")[\"precipitation\"].count()\n","\n","print(month_counts)  # Print number of entries per month\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":453,"status":"ok","timestamp":1742723570886,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"oK74-v5ua0zO","outputId":"665a1fd2-78c1-4c3c-c84f-ec6d8eb0eb2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["         lon   lat       time  precipitationQualityIndex  precipitation  \\\n","0  68.049995  6.05 2024-01-01                       3.94       0.052414   \n","1  68.049995  6.05 2024-02-01                       3.27       0.011862   \n","2  68.049995  6.05 2024-03-01                       2.74       0.002483   \n","3  68.049995  6.05 2024-06-01                       3.76       0.041103   \n","4  68.049995  6.05 2024-07-01                       4.01       0.083310   \n","\n","   probabilityLiquidPrecipitation  randomError  \n","0                           100.0        0.045  \n","1                           100.0        0.020  \n","2                           100.0        0.010  \n","3                           100.0        0.039  \n","4                           100.0        0.062  \n"]}],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","\n","# Normalize the precipitation values\n","df_filled[\"precipitation\"] = scaler.fit_transform(df_filled[[\"precipitation\"]])\n","\n","print(df_filled.head())  # Check normalized values\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1161,"status":"ok","timestamp":1742723599537,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"GkCXFMDza4u0","outputId":"f4f37381-2f78-4b17-ddb3-8f379d09a64a"},"outputs":[{"name":"stdout","output_type":"stream","text":["X shape: (671997, 3), y shape: (671997,)\n"]}],"source":["import numpy as np\n","\n","def create_sequences(data, seq_length=3):\n","    X, y = [], []\n","    for i in range(len(data) - seq_length):\n","        X.append(data[i:i+seq_length])  # Past 'seq_length' values\n","        y.append(data[i+seq_length])    # Next time step\n","    return np.array(X), np.array(y)\n","\n","# Prepare sequences for LSTM\n","seq_length = 3  # Lookback window (adjustable)\n","X, y = create_sequences(df_filled[\"precipitation\"].values, seq_length)\n","\n","print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1742723620820,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"mrOVE8BHbBLW","outputId":"0f4e813e-cb6c-4cc6-e94e-10ec3285d38f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training size: 537597, Testing size: 134400\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n","\n","print(f\"Training size: {len(X_train)}, Testing size: {len(X_test)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":368,"status":"ok","timestamp":1742723637802,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"GW2p7S11bDh7","outputId":"0870210b-398a-4f08-8736-90fa6f1df6a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train shape: (537597, 3, 1), X_test shape: (134400, 3, 1)\n"]}],"source":["# Reshape data for LSTM\n","X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n","X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n","\n","print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dIY-mF5AcNoY"},"outputs":[],"source":["y_train = y_train.reshape(-1, 1)\n","y_test = y_test.reshape(-1, 1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":1616,"status":"ok","timestamp":1742724048513,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"Pdz_cbhmbGvn","outputId":"7ccac593-9e9f-4d0f-f6df-3a79b1e2f427"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential_2\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,400</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │          \u001b[38;5;34m10,400\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m20,200\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │           \u001b[38;5;34m1,275\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m26\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,901</span> (124.61 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,901\u001b[0m (124.61 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,901</span> (124.61 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,901\u001b[0m (124.61 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout\n","\n","# Define the LSTM model\n","model = Sequential([\n","    LSTM(50, return_sequences=True, input_shape=(3, 1)),  # Ensure (timesteps, features)\n","    Dropout(0.2),\n","    LSTM(50, return_sequences=False),\n","    Dropout(0.2),\n","    Dense(25, activation=\"relu\"),\n","    Dense(1, activation=\"sigmoid\")\n","])\n","\n","# Model summary\n","model.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":776,"status":"ok","timestamp":1742723946400,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"5yj1DZoZcDY6","outputId":"cffadd6b-217a-4039-f7ef-57819542df2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train shape: (537597, 3, 1)\n","y_train shape: (537597, 1)\n"]}],"source":["print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1543484,"status":"ok","timestamp":1742725622333,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"bI21bN19cvlc","outputId":"67852615-42e7-4f34-eaf5-eaa1589fa6be"},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential_3\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,400</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │          \u001b[38;5;34m10,400\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m20,200\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │           \u001b[38;5;34m1,275\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m26\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,901</span> (124.61 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,901\u001b[0m (124.61 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,901</span> (124.61 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,901\u001b[0m (124.61 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 9ms/step - loss: 0.0088 - val_loss: 0.0070\n","Epoch 2/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0071\n","Epoch 3/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0062\n","Epoch 4/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 9ms/step - loss: 0.0033 - val_loss: 0.0063\n","Epoch 5/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0059\n","Epoch 6/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0062\n","Epoch 7/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0065\n","Epoch 8/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 8ms/step - loss: 0.0030 - val_loss: 0.0064\n","Epoch 9/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0064\n","Epoch 10/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0056\n","Epoch 11/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0062\n","Epoch 12/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0063\n","Epoch 13/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 0.0063\n","Epoch 14/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 0.0061\n","Epoch 15/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 0.0064\n","Epoch 16/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 0.0063\n","Epoch 17/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 0.0060\n","Epoch 18/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 0.0060\n","Epoch 19/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 0.0056\n","Epoch 20/20\n","\u001b[1m8400/8400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 0.0059\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout\n","\n","# Define the LSTM model\n","model = Sequential([\n","    LSTM(50, return_sequences=True, input_shape=(3, 1)),  # Ensure (timesteps, features)\n","    Dropout(0.2),\n","    LSTM(50, return_sequences=False),\n","    Dropout(0.2),\n","    Dense(25, activation=\"relu\"),\n","    Dense(1, activation=\"sigmoid\")\n","])\n","\n","# Model summary\n","model.summary()\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='mse') # Example using 'adam' optimizer and 'mse' loss\n","                                           # You can adjust these based on your needs\n","\n","history = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":665,"status":"ok","timestamp":1742725778537,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"R4bceHYgix13","outputId":"1d3b9b76-5fa3-41b4-a5f3-e6179e94e42d"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Model saved successfully as flood_prediction_model.h5\n"]}],"source":["model.save(\"flood_prediction_model.keras\")\n","print(\"✅ Model saved successfully as flood_prediction_model.h5\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1415,"status":"ok","timestamp":1742725877589,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"1_ZMLba3jnSQ","outputId":"a563aa0d-dfdd-4c2a-c76f-46d37731bcf1"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Model loaded successfully!\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 12 variables whereas the saved optimizer has 22 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]}],"source":["from tensorflow.keras.models import load_model\n","\n","model = load_model(\"flood_prediction_model.keras\")\n","print(\"✅ Model loaded successfully!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12686,"status":"ok","timestamp":1742725974135,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"tNKFhpn2jppR","outputId":"cb04feeb-8b10-4e13-f292-1082d7a43fb4"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m4200/4200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0066\n","📊 Model Evaluation: 0.006359281949698925\n"]}],"source":["evaluation_metrics = model.evaluate(X_test, y_test)\n","print(f\"📊 Model Evaluation: {evaluation_metrics}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14131,"status":"ok","timestamp":1742726014315,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"P9i6gm4mkF7o","outputId":"87a5d053-44a2-4e40-b0a7-87869e38c727"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m4200/4200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0066\n","📊 Model Evaluation: Loss = 0.0064\n"]}],"source":["evaluation_metrics = model.evaluate(X_test, y_test)\n","\n","if isinstance(evaluation_metrics, (list, tuple)):\n","    loss, mae = evaluation_metrics\n","    print(f\"📊 Model Evaluation: Loss = {loss:.4f}, MAE = {mae:.4f}\")\n","else:\n","    loss = evaluation_metrics  # If only loss is returned\n","    print(f\"📊 Model Evaluation: Loss = {loss:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21122,"status":"ok","timestamp":1742726163523,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"X9hq0GIrkovE","outputId":"0fbca092-a86d-40e4-fad2-61c6b102d364"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m4200/4200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step\n","[[0.02083854]\n"," [0.110149  ]\n"," [0.01073393]\n"," [0.04413974]\n"," [0.07634331]\n"," [0.05263359]\n"," [0.06822101]\n"," [0.09858719]\n"," [0.01267175]\n"," [0.00389596]]\n"]}],"source":["y_pred = model.predict(X_test)\n","print(y_pred[:10])  # Show first 10 predictions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":910,"status":"ok","timestamp":1742726189238,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"jrfjuMIWk0A8","outputId":"5e23974f-890e-4ec4-b917-1667728ccb94"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low']\n"]}],"source":["def categorize_flood_severity(predictions):\n","    categories = []\n","    for value in predictions:\n","        if value < 0.3:\n","            categories.append(\"Low\")\n","        elif 0.3 <= value < 0.7:\n","            categories.append(\"Medium\")\n","        else:\n","            categories.append(\"Extreme\")\n","    return categories\n","\n","flood_severity = categorize_flood_severity(y_pred.flatten())\n","print(flood_severity[:10])  # Show first 10 classified results\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":376,"status":"ok","timestamp":1742904805607,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"r05d1MEtJbiL","outputId":"2b210f34-2172-4a2f-9177-46436e2cd982"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Preprocessing completed! Saved as /content/drive/MyDrive/Colab Notebooks/Nasa Floods/processed_india_floods.nc4\n"]}],"source":["# Step 1: Install & Import Required Libraries\n","import xarray as xr\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Step 2: Load the .nc4 dataset\n","file_path = \"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/merged_dataset.nc4\"  # Replace with your file path\n","ds = xr.open_dataset(file_path)\n","\n","# Step 3: Extract India-specific data (Lat: 6N-38N, Lon: 68E-98E)\n","lat_min, lat_max = 6.0, 38.0\n","lon_min, lon_max = 68.0, 98.0\n","\n","ds_india = ds.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n","\n","# Step 4: Convert Time Format (Unix to Datetime)\n","ds_india[\"time\"] = pd.to_datetime(ds_india[\"time\"].values)\n","\n","# Step 5: Handle Missing Values (-9999.9, -9999)\n","precip = ds_india[\"precipitation\"].values\n","missing_values = [-9999.9, -9999]\n","\n","# Replace missing values with NaN\n","for mv in missing_values:\n","    precip[precip == mv] = np.nan\n","\n","# Fill NaN using median interpolation\n","median_value = np.nanmedian(precip)\n","precip = np.nan_to_num(precip, nan=median_value)\n","\n","# Step 6: Detect & Handle Outliers using IQR\n","Q1 = np.percentile(precip, 25)\n","Q3 = np.percentile(precip, 75)\n","IQR = Q3 - Q1\n","\n","# Define outlier threshold\n","lower_bound = Q1 - 1.5 * IQR\n","upper_bound = Q3 + 1.5 * IQR\n","\n","# Replace outliers with median value\n","precip = np.where((precip < lower_bound) | (precip > upper_bound), median_value, precip)\n","\n","# Step 7: Normalize Precipitation Data (Min-Max Scaling)\n","scaler = MinMaxScaler()\n","precip_reshaped = precip.reshape(-1, 1)  # Reshape for scaling\n","precip_scaled = scaler.fit_transform(precip_reshaped).reshape(precip.shape)\n","\n","# Step 8: Store processed data back in xarray dataset\n","ds_india[\"precipitation\"].values = precip_scaled\n","\n","# Step 9: Save Preprocessed Dataset in .nc4 Format\n","output_path = \"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/processed_india_floods.nc4\"\n","ds_india.to_netcdf(output_path)\n","\n","print(f\"✅ Preprocessing completed! Saved as {output_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":412,"status":"ok","timestamp":1742904685219,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"ZyFD2dn9NYCj","outputId":"ed4f886d-1cff-473f-a6e4-716e697ee34a"},"outputs":[{"name":"stdout","output_type":"stream","text":["<xarray.Dataset> Size: 11MB\n","Dimensions:                         (lon: 300, lat: 320, time: 7)\n","Coordinates:\n","  * lon                             (lon) float32 1kB 68.05 68.15 ... 97.95\n","  * lat                             (lat) float32 1kB 6.05 6.15 ... 37.85 37.95\n","  * time                            (time) datetime64[ns] 56B 2024-01-01 ... ...\n","Data variables:\n","    precipitationQualityIndex       (time, lon, lat) float32 3MB ...\n","    precipitation                   (time, lon, lat) float32 3MB 0.253 ... 0....\n","    probabilityLiquidPrecipitation  (time, lon, lat) float32 3MB ...\n","    randomError                     (time, lon, lat) float32 3MB ...\n","Attributes:\n","    FileHeader:                      DOI=10.5067/GPM/IMERG/3B-MONTH/07;\\nDOIa...\n","    FileInfo:                        DataFormatVersion=7e;\\nTKCodeBuildVersio...\n","    Grid.GridHeader:                 BinMethod=ARITHMETIC_MEAN;\\nRegistration...\n","    Grid.fullnamepath:               /Grid\n","    DODS_EXTRA.Unlimited_Dimension:  time\n","    history:                         2025-03-23 06:23:20 GMT hyrax-1.17.1 htt...\n","    history_json:                    [{\"$schema\":\"https:\\/\\/harmony.earthdata...\n"]}],"source":["print(ds_india)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11225,"status":"ok","timestamp":1742927945301,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"KmUbL_OXSExM","outputId":"a196bdc4-7c22-4743-eada-32510120e23f"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Data Prepared for BiLSTM Training!\n","X_train shape: (307200, 3, 1), y_train shape: (307200, 3)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import xarray as xr\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Load dataset\n","ds = xr.open_dataset('/content/drive/MyDrive/Colab Notebooks/Nasa Floods/processed_india_floods.nc4')\n","df = ds.to_dataframe().reset_index()\n","\n","# ✅ 1️⃣ Temporal Features\n","df['month'] = df['time'].dt.month\n","df['year'] = df['time'].dt.year\n","\n","# Map seasons\n","season_map = {6: 'monsoon', 7: 'monsoon', 8: 'monsoon', 9: 'monsoon',\n","              10: 'post-monsoon', 11: 'post-monsoon',\n","              12: 'winter', 1: 'winter', 2: 'winter',\n","              3: 'pre-monsoon', 4: 'pre-monsoon', 5: 'pre-monsoon'}\n","df['season'] = df['month'].map(season_map)\n","\n","# ✅ 2️⃣ Region Classification (Improved)\n","def classify_region(lat, lon):\n","    if lat > 25: return 'North'\n","    elif lat > 20 and lon > 80: return 'East'\n","    elif lat > 20: return 'West'\n","    else: return 'South'\n","\n","df['region'] = df.apply(lambda row: classify_region(row['lat'], row['lon']), axis=1)\n","\n","# ✅ 3️⃣ Rainfall-Based Features\n","df['precip_rolling_3m'] = df.groupby(['lat', 'lon'])['precipitation'].transform(lambda x: x.rolling(3, min_periods=1).mean())\n","df['precip_anomaly'] = df.groupby(['lat', 'lon'])['precipitation'].transform(lambda x: x - x.mean())\n","\n","# ✅ 4️⃣ Heavy Rainfall Flag (Above 90th Percentile for more sensitivity)\n","df['heavy_rain'] = (df['precipitation'] > df['precipitation'].quantile(0.90)).astype(int)\n","\n","# ✅ 5️⃣ Flood Risk Classification (Revised Thresholds)\n","def classify_flood_risk(precip):\n","    if precip < 0.2: return 0  # Low risk\n","    elif precip < 0.6: return 1  # Medium risk\n","    else: return 2  # High risk\n","\n","df['flood_risk'] = df['precipitation'].apply(classify_flood_risk)\n","\n","# ✅ 6️⃣ Normalize AFTER Feature Engineering\n","scaler = MinMaxScaler()\n","df[['precipitation', 'precip_rolling_3m', 'precip_anomaly']] = scaler.fit_transform(df[['precipitation', 'precip_rolling_3m', 'precip_anomaly']])\n","\n","# ✅ 7️⃣ Save Processed Data\n","ds_new = xr.Dataset.from_dataframe(df)\n","ds_new.to_netcdf(\"processed_india_floods.nc4\")\n","\n","print(\"✅ Preprocessing Completed! Data saved as processed_india_floods.nc4\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14279,"status":"ok","timestamp":1742928063774,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"UnawKbBKXtQP","outputId":"1a31667a-b36d-4f77-f89a-cd2f18c91eca"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Data Prepared for BiLSTM Training!\n","X_train shape: (307200, 3, 1), y_train shape: (307200, 3)\n"]}],"source":["import xarray as xr\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","\n","# Load Processed Dataset\n","data_path = \"processed_india_floods.nc4\"\n","dataset = xr.open_dataset(data_path)\n","\n","#  Convert Xarray to Pandas\n","df = dataset.to_dataframe().reset_index()\n","\n","#  Define Sequence Length for BiLSTM\n","seq_length = 3  # Using past 3 time steps for prediction\n","\n","X, y = [], []\n","\n","#  Convert Data to Sequences\n","for lat_lon, group in df.groupby(['lat', 'lon']):\n","    precip_series = group['precipitation'].values\n","    flood_series = group['flood_risk'].values\n","\n","    for i in range(len(precip_series) - seq_length):\n","        X.append(precip_series[i:i+seq_length])  # Input: past 3 time steps\n","        y.append(flood_series[i+seq_length])  # Target: next time step\n","\n","#  Convert to NumPy Arrays\n","X, y = np.array(X), np.array(y)\n","X = X.reshape(X.shape[0], X.shape[1], 1)  # Shape: (samples, time_steps, features)\n","\n","#  Convert Labels to Categorical (One-Hot Encoding)\n","y = to_categorical(y, num_classes=3)\n","\n","#  Split Data into Train & Test\n","split = int(0.8 * len(X))\n","X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n","\n","print(\" Data Prepared for BiLSTM Training!\")\n","print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1742928072208,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"KUwNP4T2SqJo","outputId":"440dfca8-9467-4371-9e48-4037ac58caaf"},"outputs":[{"name":"stdout","output_type":"stream","text":["flood_risk\n","0    459599\n","1    147752\n","2     64649\n","Name: count, dtype: int64\n"]}],"source":["print(df['flood_risk'].value_counts())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1949661,"status":"ok","timestamp":1742930345037,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"0Gw28LOjb52g","outputId":"e5a128ee-26a0-4294-b08a-0bba027b459f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 11ms/step - accuracy: 0.4873 - loss: 1.0123 - val_accuracy: 0.8005 - val_loss: 0.7776\n","Epoch 2/15\n","\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 11ms/step - accuracy: 0.5290 - loss: 0.9555 - val_accuracy: 0.8404 - val_loss: 0.6466\n","Epoch 3/15\n","\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 11ms/step - accuracy: 0.5512 - loss: 0.9188 - val_accuracy: 0.8056 - val_loss: 0.6697\n","Epoch 4/15\n","\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 11ms/step - accuracy: 0.5601 - loss: 0.9009 - val_accuracy: 0.7435 - val_loss: 0.6200\n","Epoch 5/15\n","\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 11ms/step - accuracy: 0.5663 - loss: 0.8909 - val_accuracy: 0.7591 - val_loss: 0.6326\n","Epoch 6/15\n","\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 11ms/step - accuracy: 0.5713 - loss: 0.8827 - val_accuracy: 0.6900 - val_loss: 0.6368\n","Epoch 7/15\n","\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 11ms/step - accuracy: 0.5735 - loss: 0.8784 - val_accuracy: 0.7139 - val_loss: 0.6339\n","Epoch 8/15\n","\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 11ms/step - accuracy: 0.5779 - loss: 0.8722 - val_accuracy: 0.7274 - val_loss: 0.6367\n","Epoch 9/15\n","\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 11ms/step - accuracy: 0.5786 - loss: 0.8686 - val_accuracy: 0.6944 - val_loss: 0.6451\n","Epoch 10/15\n","\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 11ms/step - accuracy: 0.5790 - loss: 0.8670 - val_accuracy: 0.7224 - val_loss: 0.6230\n","Epoch 11/15\n","\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 11ms/step - accuracy: 0.5837 - loss: 0.8613 - val_accuracy: 0.7305 - val_loss: 0.6304\n","Epoch 12/15\n","\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 11ms/step - accuracy: 0.5834 - loss: 0.8624 - val_accuracy: 0.6576 - val_loss: 0.6949\n","Epoch 13/15\n","\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 11ms/step - accuracy: 0.5873 - loss: 0.8548 - val_accuracy: 0.6698 - val_loss: 0.6763\n","Epoch 14/15\n","\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 11ms/step - accuracy: 0.5888 - loss: 0.8544 - val_accuracy: 0.6471 - val_loss: 0.7057\n","Epoch 15/15\n","\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 11ms/step - accuracy: 0.5877 - loss: 0.8548 - val_accuracy: 0.6578 - val_loss: 0.6762\n","✅ BiLSTM Model Training Complete!\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n","\n","#  Define BiLSTM Model\n","model = Sequential([\n","    Bidirectional(LSTM(64, return_sequences=True, input_shape=(seq_length, 1))),\n","    Dropout(0.2),\n","    Bidirectional(LSTM(32)),\n","    Dense(16, activation=\"relu\"),\n","    Dropout(0.2),\n","    Dense(3, activation=\"softmax\")  # 3 Flood Risk Levels: Low, Medium, High\n","])\n","\n","# Compile Model\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train Model\n","history = model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_test, y_test))\n","\n","print(\" BiLSTM Model Training Complete!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fjrURkUEw-FH"},"outputs":[],"source":["model.save('/content/drive/MyDrive/Colab Notebooks/Nasa Floods/predict_flood.keras')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12294,"status":"ok","timestamp":1742931071681,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"TgdqjUKagSvs","outputId":"9ab3dab4-beff-40e0-f5a8-f40ced7ae06b"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Data Prepared for BiLSTM Training!\n","X_train shape: (307200, 3, 1), y_train shape: (307200, 3)\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import xarray as xr\n","\n","# ✅ Load the Previous Model\n","model = tf.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/predict_flood.keras\")  # Load your last saved model\n","\n","\n","# ✅ Load Processed Dataset\n","data_path = \"processed_india_floods.nc4\"\n","dataset = xr.open_dataset(data_path)\n","\n","# ✅ Convert Xarray to Pandas\n","df = dataset.to_dataframe().reset_index()\n","\n","# ✅ Define Sequence Length for BiLSTM\n","seq_length = 3  # Using past 3 time steps for prediction\n","\n","X, y = [], []\n","\n","# ✅ Convert Data to Sequences\n","for lat_lon, group in df.groupby(['lat', 'lon']):\n","    precip_series = group['precipitation'].values\n","    flood_series = group['flood_risk'].values\n","\n","    for i in range(len(precip_series) - seq_length):\n","        X.append(precip_series[i:i+seq_length])  # Input: past 3 time steps\n","        y.append(flood_series[i+seq_length])  # Target: next time step\n","\n","# ✅ Convert to NumPy Arrays\n","X, y = np.array(X), np.array(y)\n","X = X.reshape(X.shape[0], X.shape[1], 1)  # Shape: (samples, time_steps, features)\n","\n","# ✅ Convert Labels to Categorical (One-Hot Encoding)\n","y = to_categorical(y, num_classes=3)\n","\n","# ✅ Split Data into Train & Test\n","split = int(0.8 * len(X))\n","X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n","\n","print(\"✅ Data Prepared for BiLSTM Training!\")\n","print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":764404,"status":"ok","timestamp":1742931873576,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"LORteC6XyaDS","outputId":"3f2d9ca3-b742-4855-b4c9-d85fc37f059c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 13ms/step - accuracy: 0.5933 - loss: 0.8457 - val_accuracy: 0.6677 - val_loss: 0.6795\n","Epoch 2/10\n","\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 13ms/step - accuracy: 0.5925 - loss: 0.8462 - val_accuracy: 0.6997 - val_loss: 0.6641\n","Epoch 3/10\n","\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 14ms/step - accuracy: 0.5940 - loss: 0.8455 - val_accuracy: 0.6639 - val_loss: 0.6854\n","Epoch 4/10\n","\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 13ms/step - accuracy: 0.5939 - loss: 0.8440 - val_accuracy: 0.7054 - val_loss: 0.6575\n","Epoch 5/10\n","\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 13ms/step - accuracy: 0.5945 - loss: 0.8420 - val_accuracy: 0.6744 - val_loss: 0.6754\n","Epoch 6/10\n","\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 14ms/step - accuracy: 0.5941 - loss: 0.8433 - val_accuracy: 0.6976 - val_loss: 0.6605\n","Epoch 7/10\n","\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 14ms/step - accuracy: 0.5960 - loss: 0.8396 - val_accuracy: 0.6676 - val_loss: 0.7054\n","Epoch 8/10\n","\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 14ms/step - accuracy: 0.5970 - loss: 0.8404 - val_accuracy: 0.7156 - val_loss: 0.6359\n","Epoch 9/10\n","\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 14ms/step - accuracy: 0.5955 - loss: 0.8405 - val_accuracy: 0.6830 - val_loss: 0.6730\n","Epoch 10/10\n","\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 13ms/step - accuracy: 0.5968 - loss: 0.8385 - val_accuracy: 0.7152 - val_loss: 0.6504\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["✅ Training Continued & Model Saved as improved_flood_bilstm.h5\n"]}],"source":["# ✅ Resume Training on the Same Data\n","history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)\n","\n","# ✅ Save the Improved Model\n","model.save(\"improved_flood_bilstm.h5\")\n","print(\"✅ Training Continued & Model Saved as improved_flood_bilstm.h5\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12053,"status":"ok","timestamp":1742931985250,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"oqdLYORz1yCu","outputId":"158f30be-baba-44f2-8916-0cdd79723175"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.6837 - loss: 0.7209\n","✅ New Test Accuracy: 0.7152\n"]}],"source":["# ✅ Load the New Model\n","new_model = tf.keras.models.load_model(\"improved_flood_bilstm.h5\")\n","\n","# ✅ Evaluate on Test Data\n","loss, accuracy = new_model.evaluate(X_test, y_test)\n","print(f\"✅ New Test Accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8DM4t5ms57K7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":149056,"status":"ok","timestamp":1742933777498,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"2tfxTkmM4_L1","outputId":"3c7b92cd-c6ce-4145-8439-0d3309a109b8"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12000/12000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3ms/step\n","✅ Predictions saved to flood_predictions.csv\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import xarray as xr\n","from tensorflow.keras.models import load_model\n","\n","# Load the processed dataset\n","data_path = \"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/processed_india_floods.nc4\"  # Update with correct path\n","ds = xr.open_dataset(data_path)\n","df = ds.to_dataframe().reset_index()\n","\n","# Load the trained BiLSTM model\n","model_path = \"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/improved_flood_bilstm.h5\"  # Update with actual model path\n","model = load_model(model_path)\n","\n","# Sequence length used in training\n","seq_length = 3\n","\n","# Function to create sequences for prediction\n","def create_sequences(df, seq_length):\n","    X_pred = []\n","    coords = []  # To store lat, lon, and time\n","\n","    grouped = df.groupby(['lat', 'lon'])\n","    for (lat, lon), group in grouped:\n","        group = group.sort_values('time')\n","\n","        precip_series = group['precipitation'].values\n","\n","        for i in range(len(precip_series) - seq_length):\n","            X_pred.append(precip_series[i:i+seq_length])\n","            coords.append((lat, lon, group['time'].iloc[i + seq_length]))\n","\n","    return np.array(X_pred), coords\n","\n","# Create sequences\n","X_pred, coords = create_sequences(df, seq_length)\n","X_pred = X_pred.reshape(X_pred.shape[0], X_pred.shape[1], 1)\n","\n","# Generate predictions\n","predictions = model.predict(X_pred)\n","predicted_risk = np.argmax(predictions, axis=1)  # Convert to categorical values (0: Low, 1: Medium, 2: High)\n","\n","# Convert to DataFrame\n","prediction_df = pd.DataFrame(coords, columns=['lat', 'lon', 'time'])\n","prediction_df['predicted_risk'] = predicted_risk\n","\n","# Merge with original data for additional insights\n","final_df = prediction_df.merge(df, on=['lat', 'lon', 'time'], how='left')\n","\n","# Save to CSV\n","csv_path = \"flood_predictions.csv\"\n","final_df.to_csv(csv_path, index=False)\n","\n","print(f\"✅ Predictions saved to {csv_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48,"status":"ok","timestamp":1742919399167,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"c1uuP64ZF2rv","outputId":"c2c2a8af-bddd-496a-a512-78167dce7fb1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape before reshaping: (3, 320, 300)\n"]}],"source":["print(\"Shape before reshaping:\", dataset['precipitation'][-seq_length:].values.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11036,"status":"ok","timestamp":1743410541754,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"1428u6aBXJn2","outputId":"1e96bd55-d799-4b3a-ffc3-425b47f867b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total flood points: 384000\n","Flood points inside India: 111472\n","Sample points inside India:\n","        lat    lon                State\n","10632  6.85  93.85  Andaman and Nicobar\n","10633  6.85  93.85  Andaman and Nicobar\n","10634  6.85  93.85  Andaman and Nicobar\n","10635  6.85  93.85  Andaman and Nicobar\n","11828  6.95  93.75  Andaman and Nicobar\n"]}],"source":["import pandas as pd\n","import geopandas as gpd\n","from shapely.geometry import Point\n","\n","# Load India states shapefile\n","india_states = gpd.read_file(\"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/india_state.geojson\")\n","india_states = india_states.to_crs(epsg=4326)  # Ensure correct CRS\n","\n","# Load flood prediction CSV\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/flood_predictions.csv\")\n","\n","# Convert lat/lon to geometric points\n","df[\"geometry\"] = df.apply(lambda row: Point(row[\"lon\"], row[\"lat\"]), axis=1)\n","gdf = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")\n","\n","# Spatial join: assign state names to each flood point\n","gdf = gpd.sjoin(gdf, india_states, how=\"left\", predicate=\"within\")\n","gdf.rename(columns={\"NAME_1\": \"State\"}, inplace=True)\n","\n","# Count how many points got a state assigned\n","print(f\"Total flood points: {len(gdf)}\")\n","print(f\"Flood points inside India: {gdf['State'].notna().sum()}\")\n","print(\"Sample points inside India:\")\n","print(gdf[gdf[\"State\"].notna()][[\"lat\", \"lon\", \"State\"]].head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79316,"status":"ok","timestamp":1743412011563,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"YxnjvfBCabiH","outputId":"8b0b3c51-c0bc-4812-f09f-5b2d58928924"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Nearest states assigned & saved.\n"]}],"source":["import pandas as pd\n","import geopandas as gpd\n","from shapely.geometry import Point\n","from scipy.spatial import cKDTree\n","\n","# **1️⃣ Load India states shapefile**\n","india_states = gpd.read_file(\"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/india_state.geojson\")\n","\n","# Convert to projected CRS for accurate centroid calculation\n","india_states = india_states.to_crs(epsg=3857)\n","\n","# Compute centroids in projected CRS\n","state_centroids = india_states.geometry.centroid\n","\n","# Convert back to WGS 84 (EPSG:4326) for mapping\n","india_states = india_states.to_crs(epsg=4326)\n","state_centroids = state_centroids.to_crs(epsg=4326)\n","\n","# **2️⃣ Load Flood Data (CSV)**\n","flood_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/flood_predictions.csv\")\n","\n","# **3️⃣ Convert lat/lon to geometry (GeoDataFrame)**\n","flood_gdf = gpd.GeoDataFrame(flood_df,\n","                             geometry=gpd.points_from_xy(flood_df.lon, flood_df.lat),\n","                             crs=\"EPSG:4326\")\n","\n","# **🛠 FIX: Add \"State\" column if missing**\n","if \"State\" not in flood_gdf.columns:\n","    flood_gdf[\"State\"] = None  # Create an empty State column\n","\n","# **4️⃣ Build KDTree for Nearest State Lookup**\n","tree = cKDTree(list(zip(state_centroids.x, state_centroids.y)))\n","\n","def find_nearest_state_fast(point):\n","    \"\"\"Find the nearest state for ocean points.\"\"\"\n","    _, idx = tree.query([point.x, point.y])\n","    return india_states.iloc[idx][\"NAME_1\"]  # Get nearest state name\n","\n","# **5️⃣ Find Missing States**\n","missing_state = flood_gdf[flood_gdf[\"State\"].isna()]\n","\n","# Apply nearest state function only to missing rows\n","missing_state[\"State\"] = missing_state[\"geometry\"].apply(find_nearest_state_fast)\n","\n","# Merge back into main dataset\n","flood_gdf.update(missing_state)\n","\n","# **6️⃣ Save the Updated Data**\n","flood_gdf.to_csv(\"flood_predictions_with_states.csv\", index=False)\n","print(\"✅ Nearest states assigned & saved.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":867,"status":"ok","timestamp":1743412065845,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"bQMMkQeRdODz","outputId":"b4d357f3-781b-4dc7-cdd3-4766a231aeee"},"outputs":[{"name":"stdout","output_type":"stream","text":["    lat        lon        time  predicted_risk  precipitationQualityIndex  \\\n","0  6.05  68.049995  2024-06-01               0                       3.76   \n","1  6.05  68.049995  2024-07-01               0                       4.01   \n","2  6.05  68.049995  2024-08-01               1                       3.97   \n","3  6.05  68.049995  2024-09-01               1                       3.60   \n","4  6.05  68.150000  2024-06-01               0                       3.76   \n","\n","   precipitation  probabilityLiquidPrecipitation  randomError  \\\n","0       0.198402                           100.0        0.039   \n","1       0.402130                           100.0        0.062   \n","2       0.318242                           100.0        0.053   \n","3       0.105193                           100.0        0.027   \n","4       0.191744                           100.0        0.038   \n","\n","   precip_3day_avg  precip_7day_avg  flood_risk  precip_zscore  is_anomaly  \\\n","0         0.089214         0.130160           0       0.036226           0   \n","1         0.204172         0.184554           0       0.869124           0   \n","2         0.306258         0.206835           0       0.526166           0   \n","3         0.275189         0.192315           0      -0.344839           0   \n","4         0.088327         0.200114           0       0.009007           0   \n","\n","   month  is_monsoon  precip_lag_1  precip_lag_3            geometry  \\\n","0      6           1      0.011984      0.252996  POINT (68.05 6.05)   \n","1      7           1      0.198402      0.057257  POINT (68.05 6.05)   \n","2      8           1      0.402130      0.011984  POINT (68.05 6.05)   \n","3      9           1      0.318242      0.198402  POINT (68.05 6.05)   \n","4      6           1      0.010652      0.310253  POINT (68.15 6.05)   \n","\n","         State  \n","0  Lakshadweep  \n","1  Lakshadweep  \n","2  Lakshadweep  \n","3  Lakshadweep  \n","4  Lakshadweep  \n","['Lakshadweep' 'Kerala' 'Tamil Nadu' 'Andaman and Nicobar' 'Puducherry'\n"," 'Karnataka' 'Goa' 'Andhra Pradesh' 'Orissa' 'Daman and Diu' 'Maharashtra'\n"," 'Dadra and Nagar Haveli' 'Mizoram' 'Tripura' 'Chhattisgarh' 'West Bengal'\n"," 'Madhya Pradesh' 'Manipur' 'Gujarat' 'Jharkhand' 'Rajasthan' 'Nagaland'\n"," 'Uttar Pradesh' 'Meghalaya' 'Bihar' 'Assam' 'Sikkim' 'Delhi'\n"," 'Arunachal Pradesh' 'Haryana' 'Uttaranchal' 'Punjab' 'Chandigarh'\n"," 'Himachal Pradesh' 'Jammu and Kashmir']\n"]}],"source":["print(flood_gdf.head())  # Check first few rows\n","print(flood_gdf[\"State\"].unique())  # List all assigned states\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":636,"status":"ok","timestamp":1743412153086,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"HcmKGn9cdjJ9","outputId":"5ec7c6e8-b43e-49a3-fda0-b18546c2f102"},"outputs":[{"name":"stdout","output_type":"stream","text":["       lat        lon                State  precipitation  flood_risk\n","251   6.05  74.250000          Lakshadweep       0.153129           0\n","255   6.05  74.350000          Lakshadweep       0.183755           0\n","337   6.05  76.450000               Kerala       0.151798           0\n","341   6.05  76.549995               Kerala       0.145140           0\n","345   6.05  76.650000               Kerala       0.145140           0\n","353   6.05  76.850000               Kerala       0.150466           0\n","369   6.05  77.250000               Kerala       0.191744           0\n","409   6.05  78.250000               Kerala       0.201065           0\n","663   6.05  84.549995           Tamil Nadu       0.082557           0\n","667   6.05  84.650000           Tamil Nadu       0.081225           0\n","826   6.05  88.650000  Andaman and Nicobar       0.213049           0\n","830   6.05  88.750000  Andaman and Nicobar       0.230360           0\n","910   6.05  90.750000  Andaman and Nicobar       0.404794           0\n","935   6.05  91.350000  Andaman and Nicobar       0.740346           0\n","943   6.05  91.549995  Andaman and Nicobar       0.656458           0\n","947   6.05  91.650000  Andaman and Nicobar       0.623169           0\n","951   6.05  91.750000  Andaman and Nicobar       0.548602           0\n","1014  6.05  93.350000  Andaman and Nicobar       0.438083           0\n","1165  6.05  97.150000  Andaman and Nicobar       0.141145           0\n","1169  6.05  97.250000  Andaman and Nicobar       0.146471           0\n"]}],"source":["high_risk_floods = flood_gdf[flood_gdf[\"predicted_risk\"] == 2]\n","print(high_risk_floods[[\"lat\", \"lon\", \"State\", \"precipitation\", \"flood_risk\"]].head(20))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1041,"status":"ok","timestamp":1743412189430,"user":{"displayName":"Pebin Joseph","userId":"02157217090346502568"},"user_tz":-330},"id":"6RE7y22sdsXj","outputId":"384632e9-db1d-4e2e-ec6c-b0f346b2cd68"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ High-risk flood states saved!\n"]}],"source":["high_risk_floods.to_csv(\"high_risk_flood_states.csv\", index=False)\n","print(\"✅ High-risk flood states saved!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"owIYrFEYebYy","outputId":"e4001ab4-70f9-4897-b4a7-43450cf7c5be"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ High-risk flood map saved as 'high_risk_flood_map.html'\n","Buffered data was truncated after reaching the output size limit."]}],"source":["import folium\n","import geopandas as gpd\n","import pandas as pd\n","from folium.plugins import MarkerCluster\n","\n","# Load flood predictions CSV\n","flood_df = pd.read_csv(\"high_risk_flood_states.csv\")\n","\n","# Load India states shapefile (GeoJSON)\n","india_states = gpd.read_file(\"/content/drive/MyDrive/Colab Notebooks/Nasa Floods/india_state.geojson\")\n","\n","# Create a Folium map centered in India\n","m = folium.Map(location=[20.5937, 78.9629], zoom_start=5)\n","\n","# Add state boundaries\n","folium.GeoJson(\n","    india_states,\n","    name=\"State Boundaries\",\n","    style_function=lambda x: {\n","        \"fillColor\": \"none\",\n","        \"color\": \"blue\",\n","        \"weight\": 1.5,\n","    },\n","    tooltip=folium.GeoJsonTooltip(fields=[\"NAME_1\"], aliases=[\"State:\"]),\n",").add_to(m)\n","\n","# Add high-risk flood locations (Red markers)\n","marker_cluster = MarkerCluster().add_to(m)\n","for _, row in flood_df.iterrows():\n","    folium.CircleMarker(\n","        location=[row[\"lat\"], row[\"lon\"]],\n","        radius=5,\n","        color=\"red\",\n","        fill=True,\n","        fill_color=\"red\",\n","        fill_opacity=0.7,\n","        popup=folium.Popup(f\"State: {row['State']}<br>Precipitation: {row['precipitation']}\", parse_html=True),\n","    ).add_to(marker_cluster)\n","\n","# Save the map\n","m.save(\"high_risk_flood_map.html\")\n","print(\"✅ High-risk flood map saved as 'high_risk_flood_map.html'\")\n","\n","# Display in Jupyter Notebook (Optional)\n","m\n"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1f9NPT1UZB5OX6qPOUbaSFOxqRF-st8Qb","authorship_tag":"ABX9TyNYRpopu5X8eXf8X2e7NKkK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}